{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeyEsJQ4ukfd"
   },
   "source": [
    "#**Description of Notebook:**\n",
    "The following notebook uses the pretrained models described here - https://www.biorxiv.org/content/10.1101/2020.07.12.199554v1.full.pdf, and found here - https://github.com/agemagician/ProtTrans, to create embedding vectors for each sequence in the inputted dataset. Below is an example of how to create word embeddings using the T5 Uniprot50 pre-trained model using the function created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTGWVrgFumYE"
   },
   "source": [
    "#**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11558,
     "status": "ok",
     "timestamp": 1630068040339,
     "user": {
      "displayName": "Will Dee",
      "photoUrl": "",
      "userId": "18339245303983317021"
     },
     "user_tz": -60
    },
    "id": "FblVzRgjkh0e",
    "outputId": "708cc84f-5f8e-4d0f-cc9b-bf6ce892a591"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q transformers sentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 27442,
     "status": "ok",
     "timestamp": 1634724497711,
     "user": {
      "displayName": "Will Dee",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18339245303983317021"
     },
     "user_tz": -60
    },
    "id": "bqpjDTjxk08z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer, XLNetModel, XLNetTokenizer, T5EncoderModel, T5Tokenizer\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEFROCFXch6A"
   },
   "source": [
    "# Function To Extract Word Embeddings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1634724528407,
     "user": {
      "displayName": "Will Dee",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18339245303983317021"
     },
     "user_tz": -60
    },
    "id": "lTPTXTG_chHr"
   },
   "outputs": [],
   "source": [
    "class LM_EMBED:\n",
    "\n",
    "  def __init__(self, language_model, max_len, rare_aa):\n",
    "    self.lang_model = language_model\n",
    "    self.max_len = max_len\n",
    "    self.rare_aa = rare_aa\n",
    "\n",
    "    # Import tokenizer and model from ProtTrans Pre-Trained Rostlab:\n",
    "    if self.lang_model == 'BERT-BFD':\n",
    "      self.tokenizer = BertTokenizer.from_pretrained('Rostlab/prot_bert_bfd', do_lower_case=False)\n",
    "      self.model = BertModel.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "    elif self.lang_model == 'BERT':\n",
    "      self.tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "      self.model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "    elif self.lang_model == 'T5-XL-BFD':\n",
    "      self.tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", do_lower_case=False )\n",
    "      self.model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
    "      gc.collect()\n",
    "    elif self.lang_model == 'T5-XL-UNI':\n",
    "      self.tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", do_lower_case=False )\n",
    "      self.model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n",
    "      gc.collect()\n",
    "    elif self.lang_model == 'XLNET':\n",
    "      self.tokenizer = XLNetTokenizer.from_pretrained(\"Rostlab/prot_xlnet\", do_lower_case=False)\n",
    "      self.model = XLNetModel.from_pretrained(\"Rostlab/prot_xlnet\", mem_len=512)\n",
    "\n",
    "\n",
    "  # Function to use the specified model and tokenizer to create word embedding array:\n",
    "  def extract_word_embs(self, seq_df, filename):\n",
    "\n",
    "    # Setting device to GPU if available:\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Assigning model to GPU if available, and setting to eval mode:\n",
    "    self.model = self.model.to(device)\n",
    "    self.model = self.model.eval()\n",
    "\n",
    "    # Making a list of sequences from the df:\n",
    "    seqs_list = seq_df.SEQUENCE.to_list()\n",
    "\n",
    "    # Adding spaces in between sequence letters (amino acids):\n",
    "    seqs_spaced = self.add_spaces(seqs_list)\n",
    "\n",
    "    # Map Rarely Occuring Amino Acids (U, Z, O, B) to (X) if they are present in the dataset:\n",
    "    if self.rare_aa:\n",
    "      seqs_spaced = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in seqs_spaced]\n",
    "\n",
    "    # ID list tokenized:\n",
    "    ids = self.tokenizer.batch_encode_plus(seqs_spaced, add_special_tokens=True, padding = 'max_length', max_length = self.max_len)\n",
    "\n",
    "    # Retrieving the input IDs and mask for attention as tensors:\n",
    "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "\n",
    "    # Emptying cache to ensure enough memory:\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Loop to process the sequences into embeddings in batches of 10:\n",
    "    for i in range(10, len(input_ids)+10, 10):\n",
    "      if i%100 == 0:\n",
    "        print(\"Initial Embedding Batch Ending with...\", i)\n",
    "      with torch.no_grad():\n",
    "        embeddings = self.model(input_ids=input_ids[i-10:i], \n",
    "                                attention_mask=attention_mask[i-10:i])[0]\n",
    "        emb_array = embeddings.cpu().numpy()\n",
    "\n",
    "        # Creating initial array or concatenating to existing array:\n",
    "        if i==10:\n",
    "          embedding_res = emb_array\n",
    "        else:\n",
    "          embedding_res = np.concatenate((embedding_res, emb_array))\n",
    "\n",
    "    # Extracting features using the function below:\n",
    "    features = self.extract_features(embedding_res, attention_mask) \n",
    "\n",
    "    # Padding these features to a specified max length with zeros:\n",
    "    padded_arr = self.pad(features)\n",
    "\n",
    "    #Ensuring in correct location to save embeddings:\n",
    "    %cd \"INSERT_EMBEDDINGS_FOLDER_LOC\"\n",
    "\n",
    "    # Saving array:\n",
    "    print(\"Saving Embeddings...\")\n",
    "    np.save(filename, padded_arr)\n",
    "\n",
    "\n",
    "  # Function to add spaces between the amino acids in each sequence:\n",
    "  def add_spaces(self, df_col):\n",
    "    return [\" \".join(x) for x in df_col]\n",
    "\n",
    "  # Function to remove any CLS or SEP tokens, just leaving features:\n",
    "  def extract_features(self, emb_res, att_msk):\n",
    "    features = [] \n",
    "\n",
    "    for seq_num in range(len(emb_res)):\n",
    "      seq_len = (att_msk[seq_num] == 1).sum()\n",
    "\n",
    "      if self.lang_model in ['BERT-BFD', 'BERT']:\n",
    "        seq_emd = emb_res[seq_num][1:seq_len-1]\n",
    "\n",
    "      elif self.lang_model in ['T5-XL-BFD', 'T5-XL-UNI']:\n",
    "        seq_emd = emb_res[seq_num][:seq_len-1]\n",
    "\n",
    "      elif self.lang_model == 'XLNET':\n",
    "        padded_seq_len = len(att_msk[seq_num])\n",
    "        seq_emd = emb_res[seq_num][padded_seq_len-seq_len:padded_seq_len-2]\n",
    "\n",
    "      features.append(seq_emd)\n",
    "    \n",
    "    features_arr = np.array(features, dtype=object)\n",
    "\n",
    "    return features_arr\n",
    "\n",
    "  # Function to add zeros to pad all features to max length:\n",
    "  def pad(self, features):\n",
    "    dim1 = self.max_len-2   # reducing by 2 for CLS and SEP tokens which have already been removed\n",
    "    dim2 = features[0].shape[1]\n",
    "\n",
    "    for i in range(len(features)):\n",
    "      if i%100 == 0:\n",
    "        print(\"Padding Batch: \", i)\n",
    "\n",
    "      all_zeros = np.zeros((dim1, dim2))\n",
    "      all_zeros[:features[i].shape[0], :features[i].shape[1]] = features[i]\n",
    "\n",
    "      if i==0:\n",
    "        padded_arr = all_zeros\n",
    "      elif i==1:\n",
    "        padded_arr = np.stack((padded_arr, all_zeros), axis=0)\n",
    "      else:\n",
    "        reshaped_arr = all_zeros.reshape(1, all_zeros.shape[0], all_zeros.shape[1])\n",
    "        padded_arr = np.vstack((padded_arr, reshaped_arr))\n",
    "    \n",
    "    return padded_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EC\n",
    "EC_X_train = pd.read_csv('My_paper/EC_X_train_40.csv')\n",
    "EC_X_test = pd.read_csv('My_paper/EC_X_test_40.csv')\n",
    "EC_X_val = pd.read_csv('My_paper/EC_X_val_40.csv')\n",
    "#SA\n",
    "SA_X_train = pd.read_csv('My_paper/SA_X_train_40.csv')\n",
    "SA_X_test = pd.read_csv('My_paper/SA_X_test_40.csv')\n",
    "SA_X_val = pd.read_csv('My_paper/SA_X_val_40.csv')\n",
    "#PA\n",
    "PA_X_train = pd.read_csv('My_paper/PA_X_train_40.csv')\n",
    "PA_X_test = pd.read_csv('My_paper/PA_X_test_40.csv')\n",
    "PA_X_val = pd.read_csv('My_paper/PA_X_val_40.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_3BBFbDY1uP"
   },
   "source": [
    "# **Example Embeddings:**\n",
    "- Example below of how language model word embeddings were created using the T5 Model that had been pre-trained by Elnaggar et al. (Source: https://github.com/agemagician/ProtTrans) on the UniRef50 protein dataset (see here for more information on the dataset: https://www.uniprot.org/help/uniref)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cp3lBdRDBQu"
   },
   "source": [
    "##**T5XL Uniprot50 Language Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "f1c33096d0784c68914b69d2c3968151",
      "781e7f95710f40678a6b1287b9bd6826",
      "e9e25fcb9f4f4f2fae768cbf29fb0427",
      "470ac6f5da1a4fb8b2a9d75aeb0129ae",
      "9c09942041d446db823ca14193b11493",
      "71b240f7b76d4328aaafd5aae1220519",
      "bf0ed98ab2a841d59f93f10205bde6fd",
      "ddc554d78ae7403991a63d06b357083d",
      "8239461fdacb4db0985940c8ec032f83",
      "6a3a1a3615604bc99d0c02fc8dd29498",
      "d410c182b2f64aeeb9bd5923cb91db7d",
      "faa6c564df4942f4b4702df5c8c020c9",
      "7f639375bc674825a53f79a72ff77796",
      "521418909351429dab44756b7e6585c5",
      "7f95e67356584d9ba9743e3faf25ea1a",
      "b76d745fe3ab4c929f9a6eefc196010d",
      "89d6029c24d2403cbd8be6988f129a73",
      "c846ccd6af554776858511f962771c12",
      "0990280d9c704dd38da8e85d8425bc20",
      "9c8b0afd19aa4a1da68499a52acf10c8",
      "883886c874974af881b806d310cc92b8",
      "28c5b62a652043f5babc44b7814f43ac",
      "ce539392188c4357a9735ad5733dc3e1",
      "c46f0e19ebbf46b996ea87e17251421b",
      "91746fa7b3bf4005814058efd093902e",
      "ed19561ff3ce468c916f67158dfc9774",
      "95c9577ea09f45609b2eaeb6fa504b3a",
      "35c540e1c29e42d5bf9420a69a466a32",
      "5c41efabb32e4d85b1ea1d69feb7f498",
      "f790abdaa06e46f0a728dd6c8ffb05ba",
      "9d22c013c8f3406eaca7c35bb2a46889",
      "c5deb8fa4ff84ca5b3964426034d3e7b",
      "32a39184d3794617b6296ad4b08db878",
      "4b223e611d394f5b8060740cef7d196f",
      "59344b3285794e66b3e214470db5a1b2",
      "9f3880895a4e48bfac50ca81d844430c",
      "0eb90b14c1ef457f8aa5d35ff2f7e309",
      "161892df790f44d381a295fff6387583",
      "bc99a3c8c5a2443a9b0bdb16ad09bf21",
      "8df260937f9f4ad1827278a25b2487ed",
      "228b20a563164b9fba5deb8173ea0b47",
      "0153e79d7e7d4a59931312ceb66bfcae",
      "da546386e8834a37b124c65c9366b8f4",
      "a8ea54d0df714bf8a47f6956196918c8",
      "dcfcbbde05b84dbf93d2e64157306bb9",
      "96db89ceb0164922bc49e88127989c9a",
      "bb85963ad2be403c88707e3f68c41ff2",
      "cc4ba0c4ebe54e349057ff67d0393d93",
      "71bff902900c4eb6a77cb8f78fbf33ce",
      "657182243e2e4d19aba44edd61e83968",
      "da949c4509b44ef4a4251841a52229a0",
      "a6dd1469eabb42f7bd018add5e2d329c",
      "edec03194ff94585b69dd2c9e2ae6970",
      "213954ea9986487ab154b0e030fc7592",
      "5ec2393f8e1f422d831c925e6ecf164c"
     ]
    },
    "id": "2FOcNE7yYSuz",
    "outputId": "f97ed19e-4373-4cea-bb2e-3bc2e9792492",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_t5_xl_uniref50 were not used when initializing T5EncoderModel: ['decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.final_layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'lm_head.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Specifying the max sequence length in the given dataset (255 for the LMPred Dataset), \n",
    "# then adding 2 to account for special [CLS, SEP] tokens added by the language models):\n",
    "max_seq_len = 42\n",
    "T5XL_UNI_EMBED_40 = LM_EMBED('T5-XL-UNI', max_seq_len, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My dataset ##T5XL #max_len=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11632\\1818742920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mT5XL_UNI_EMBED_40\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_word_embs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEC_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"EC_X_TRAIN.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mT5XL_UNI_EMBED_40\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_word_embs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEC_X_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"EC_X_TEST.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mT5XL_UNI_EMBED_40\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_word_embs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEC_X_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"EC_X_VAL.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11632\\3375393995.py\u001b[0m in \u001b[0;36mextract_word_embs\u001b[1;34m(self, seq_df, filename)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initial Embedding Batch Ending with...\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         embeddings = self.model(input_ids=input_ids[i-10:i], \n\u001b[0m\u001b[0;32m     64\u001b[0m                                 attention_mask=attention_mask[i-10:i])[0]\n\u001b[0;32m     65\u001b[0m         \u001b[0memb_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1912\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m   1913\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1072\u001b[0m                 )\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m   1075\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[1;31m# Apply Feed Forward layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m         \u001b[1;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[0mforwarded_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    295\u001b[0m         ):\n\u001b[0;32m    296\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "T5XL_UNI_EMBED_40.extract_word_embs(EC_X_train, \"EC_X_TRAIN.npy\")\n",
    "T5XL_UNI_EMBED_40.extract_word_embs(EC_X_test, \"EC_X_TEST.npy\")\n",
    "T5XL_UNI_EMBED_40.extract_word_embs(EC_X_val, \"EC_X_VAL.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Embedding Batch Ending with... 100\n",
      "Initial Embedding Batch Ending with... 200\n",
      "Initial Embedding Batch Ending with... 300\n",
      "Initial Embedding Batch Ending with... 400\n",
      "Initial Embedding Batch Ending with... 500\n",
      "Initial Embedding Batch Ending with... 600\n",
      "Initial Embedding Batch Ending with... 700\n",
      "Initial Embedding Batch Ending with... 800\n",
      "Initial Embedding Batch Ending with... 900\n",
      "Initial Embedding Batch Ending with... 1000\n",
      "Initial Embedding Batch Ending with... 1100\n",
      "Initial Embedding Batch Ending with... 1200\n",
      "Initial Embedding Batch Ending with... 1300\n",
      "Initial Embedding Batch Ending with... 1400\n",
      "Initial Embedding Batch Ending with... 1500\n",
      "Initial Embedding Batch Ending with... 1600\n",
      "Initial Embedding Batch Ending with... 1700\n",
      "Initial Embedding Batch Ending with... 1800\n",
      "Initial Embedding Batch Ending with... 1900\n",
      "Initial Embedding Batch Ending with... 2000\n",
      "Initial Embedding Batch Ending with... 2100\n",
      "Initial Embedding Batch Ending with... 2200\n",
      "Initial Embedding Batch Ending with... 2300\n",
      "Initial Embedding Batch Ending with... 2400\n",
      "Initial Embedding Batch Ending with... 2500\n",
      "Initial Embedding Batch Ending with... 2600\n",
      "Initial Embedding Batch Ending with... 2700\n",
      "Initial Embedding Batch Ending with... 2800\n",
      "Initial Embedding Batch Ending with... 2900\n",
      "Initial Embedding Batch Ending with... 3000\n",
      "Initial Embedding Batch Ending with... 3100\n",
      "Initial Embedding Batch Ending with... 3200\n",
      "Initial Embedding Batch Ending with... 3300\n",
      "Initial Embedding Batch Ending with... 3400\n",
      "Initial Embedding Batch Ending with... 3500\n",
      "Initial Embedding Batch Ending with... 3600\n",
      "Initial Embedding Batch Ending with... 3700\n",
      "Initial Embedding Batch Ending with... 3800\n",
      "Initial Embedding Batch Ending with... 3900\n",
      "Initial Embedding Batch Ending with... 4000\n",
      "Initial Embedding Batch Ending with... 4100\n",
      "Initial Embedding Batch Ending with... 4200\n",
      "Initial Embedding Batch Ending with... 4300\n",
      "Initial Embedding Batch Ending with... 4400\n",
      "Initial Embedding Batch Ending with... 4500\n",
      "Initial Embedding Batch Ending with... 4600\n",
      "Initial Embedding Batch Ending with... 4700\n",
      "Padding Batch:  0\n",
      "Padding Batch:  100\n",
      "Padding Batch:  200\n",
      "Padding Batch:  300\n",
      "Padding Batch:  400\n",
      "Padding Batch:  500\n",
      "Padding Batch:  600\n",
      "Padding Batch:  700\n",
      "Padding Batch:  800\n",
      "Padding Batch:  900\n",
      "Padding Batch:  1000\n",
      "Padding Batch:  1100\n",
      "Padding Batch:  1200\n",
      "Padding Batch:  1300\n",
      "Padding Batch:  1400\n",
      "Padding Batch:  1500\n",
      "Padding Batch:  1600\n",
      "Padding Batch:  1700\n",
      "Padding Batch:  1800\n",
      "Padding Batch:  1900\n",
      "Padding Batch:  2000\n",
      "Padding Batch:  2100\n",
      "Padding Batch:  2200\n",
      "Padding Batch:  2300\n",
      "Padding Batch:  2400\n",
      "Padding Batch:  2500\n",
      "Padding Batch:  2600\n",
      "Padding Batch:  2700\n",
      "Padding Batch:  2800\n",
      "Padding Batch:  2900\n",
      "Padding Batch:  3000\n",
      "Padding Batch:  3100\n",
      "Padding Batch:  3200\n",
      "Padding Batch:  3300\n",
      "Padding Batch:  3400\n",
      "Padding Batch:  3500\n",
      "Padding Batch:  3600\n",
      "Padding Batch:  3700\n",
      "Padding Batch:  3800\n",
      "Padding Batch:  3900\n",
      "Padding Batch:  4000\n",
      "Padding Batch:  4100\n",
      "Padding Batch:  4200\n",
      "Padding Batch:  4300\n",
      "Padding Batch:  4400\n",
      "Padding Batch:  4500\n",
      "Padding Batch:  4600\n",
      "Padding Batch:  4700\n",
      "[WinError 2] : 'INSERT_EMBEDDINGS_FOLDER_LOC'\n",
      "C:\\Users\\User\\Documents\\Charlie\\LMPred_AMP_Prediction-main\n",
      "Saving Embeddings...\n",
      "Initial Embedding Batch Ending with... 100\n",
      "Initial Embedding Batch Ending with... 200\n",
      "Initial Embedding Batch Ending with... 300\n",
      "Initial Embedding Batch Ending with... 400\n",
      "Initial Embedding Batch Ending with... 500\n",
      "Initial Embedding Batch Ending with... 600\n",
      "Initial Embedding Batch Ending with... 700\n",
      "Initial Embedding Batch Ending with... 800\n",
      "Initial Embedding Batch Ending with... 900\n",
      "Initial Embedding Batch Ending with... 1000\n",
      "Initial Embedding Batch Ending with... 1100\n",
      "Initial Embedding Batch Ending with... 1200\n",
      "Initial Embedding Batch Ending with... 1300\n",
      "Initial Embedding Batch Ending with... 1400\n",
      "Padding Batch:  0\n",
      "Padding Batch:  100\n",
      "Padding Batch:  200\n",
      "Padding Batch:  300\n",
      "Padding Batch:  400\n",
      "Padding Batch:  500\n",
      "Padding Batch:  600\n",
      "Padding Batch:  700\n",
      "Padding Batch:  800\n",
      "Padding Batch:  900\n",
      "Padding Batch:  1000\n",
      "Padding Batch:  1100\n",
      "Padding Batch:  1200\n",
      "Padding Batch:  1300\n",
      "Padding Batch:  1400\n",
      "[WinError 2] : 'INSERT_EMBEDDINGS_FOLDER_LOC'\n",
      "C:\\Users\\User\\Documents\\Charlie\\LMPred_AMP_Prediction-main\n",
      "Saving Embeddings...\n",
      "Initial Embedding Batch Ending with... 100\n",
      "Initial Embedding Batch Ending with... 200\n",
      "Initial Embedding Batch Ending with... 300\n",
      "Initial Embedding Batch Ending with... 400\n",
      "Initial Embedding Batch Ending with... 500\n",
      "Initial Embedding Batch Ending with... 600\n",
      "Initial Embedding Batch Ending with... 700\n",
      "Initial Embedding Batch Ending with... 800\n",
      "Initial Embedding Batch Ending with... 900\n",
      "Initial Embedding Batch Ending with... 1000\n",
      "Initial Embedding Batch Ending with... 1100\n",
      "Padding Batch:  0\n",
      "Padding Batch:  100\n",
      "Padding Batch:  200\n",
      "Padding Batch:  300\n",
      "Padding Batch:  400\n",
      "Padding Batch:  500\n",
      "Padding Batch:  600\n",
      "Padding Batch:  700\n",
      "Padding Batch:  800\n",
      "Padding Batch:  900\n",
      "Padding Batch:  1000\n",
      "Padding Batch:  1100\n",
      "[WinError 2] : 'INSERT_EMBEDDINGS_FOLDER_LOC'\n",
      "C:\\Users\\User\\Documents\\Charlie\\LMPred_AMP_Prediction-main\n",
      "Saving Embeddings...\n"
     ]
    }
   ],
   "source": [
    "T5XL_UNI_EMBED_40.extract_word_embs(SA_X_train, \"SA_X_TRAIN.npy\")\n",
    "T5XL_UNI_EMBED_40.extract_word_embs(SA_X_test, \"SA_X_TEST.npy\")\n",
    "T5XL_UNI_EMBED_40.extract_word_embs(SA_X_val, \"SA_X_VAL.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Embedding Batch Ending with... 100\n",
      "Initial Embedding Batch Ending with... 200\n",
      "Initial Embedding Batch Ending with... 300\n",
      "Initial Embedding Batch Ending with... 400\n",
      "Initial Embedding Batch Ending with... 500\n",
      "Initial Embedding Batch Ending with... 600\n",
      "Initial Embedding Batch Ending with... 700\n",
      "Initial Embedding Batch Ending with... 800\n",
      "Initial Embedding Batch Ending with... 900\n",
      "Initial Embedding Batch Ending with... 1000\n",
      "Initial Embedding Batch Ending with... 1100\n",
      "Initial Embedding Batch Ending with... 1200\n",
      "Initial Embedding Batch Ending with... 1300\n",
      "Initial Embedding Batch Ending with... 1400\n",
      "Initial Embedding Batch Ending with... 1500\n",
      "Initial Embedding Batch Ending with... 1600\n",
      "Initial Embedding Batch Ending with... 1700\n",
      "Initial Embedding Batch Ending with... 1800\n",
      "Initial Embedding Batch Ending with... 1900\n",
      "Initial Embedding Batch Ending with... 2000\n",
      "Initial Embedding Batch Ending with... 2100\n",
      "Initial Embedding Batch Ending with... 2200\n",
      "Initial Embedding Batch Ending with... 2300\n",
      "Initial Embedding Batch Ending with... 2400\n",
      "Initial Embedding Batch Ending with... 2500\n",
      "Initial Embedding Batch Ending with... 2600\n",
      "Initial Embedding Batch Ending with... 2700\n",
      "Initial Embedding Batch Ending with... 2800\n",
      "Initial Embedding Batch Ending with... 2900\n",
      "Initial Embedding Batch Ending with... 3000\n",
      "Initial Embedding Batch Ending with... 3100\n",
      "Initial Embedding Batch Ending with... 3200\n",
      "Initial Embedding Batch Ending with... 3300\n",
      "Initial Embedding Batch Ending with... 3400\n",
      "Initial Embedding Batch Ending with... 3500\n",
      "Padding Batch:  0\n",
      "Padding Batch:  100\n",
      "Padding Batch:  200\n",
      "Padding Batch:  300\n",
      "Padding Batch:  400\n",
      "Padding Batch:  500\n",
      "Padding Batch:  600\n",
      "Padding Batch:  700\n",
      "Padding Batch:  800\n",
      "Padding Batch:  900\n",
      "Padding Batch:  1000\n",
      "Padding Batch:  1100\n",
      "Padding Batch:  1200\n",
      "Padding Batch:  1300\n",
      "Padding Batch:  1400\n",
      "Padding Batch:  1500\n",
      "Padding Batch:  1600\n",
      "Padding Batch:  1700\n",
      "Padding Batch:  1800\n",
      "Padding Batch:  1900\n",
      "Padding Batch:  2000\n",
      "Padding Batch:  2100\n",
      "Padding Batch:  2200\n",
      "Padding Batch:  2300\n",
      "Padding Batch:  2400\n",
      "Padding Batch:  2500\n",
      "Padding Batch:  2600\n",
      "Padding Batch:  2700\n",
      "Padding Batch:  2800\n",
      "Padding Batch:  2900\n",
      "Padding Batch:  3000\n",
      "Padding Batch:  3100\n",
      "Padding Batch:  3200\n",
      "Padding Batch:  3300\n",
      "Padding Batch:  3400\n",
      "Padding Batch:  3500\n",
      "[WinError 2] : 'INSERT_EMBEDDINGS_FOLDER_LOC'\n",
      "C:\\Users\\User\\Documents\\Charlie\\LMPred_AMP_Prediction-main\n",
      "Saving Embeddings...\n",
      "Initial Embedding Batch Ending with... 100\n",
      "Initial Embedding Batch Ending with... 200\n",
      "Initial Embedding Batch Ending with... 300\n",
      "Initial Embedding Batch Ending with... 400\n",
      "Initial Embedding Batch Ending with... 500\n",
      "Initial Embedding Batch Ending with... 600\n",
      "Initial Embedding Batch Ending with... 700\n",
      "Initial Embedding Batch Ending with... 800\n",
      "Initial Embedding Batch Ending with... 900\n",
      "Initial Embedding Batch Ending with... 1000\n",
      "Initial Embedding Batch Ending with... 1100\n",
      "Padding Batch:  0\n",
      "Padding Batch:  100\n",
      "Padding Batch:  200\n",
      "Padding Batch:  300\n",
      "Padding Batch:  400\n",
      "Padding Batch:  500\n",
      "Padding Batch:  600\n",
      "Padding Batch:  700\n",
      "Padding Batch:  800\n",
      "Padding Batch:  900\n",
      "Padding Batch:  1000\n",
      "Padding Batch:  1100\n",
      "[WinError 2] : 'INSERT_EMBEDDINGS_FOLDER_LOC'\n",
      "C:\\Users\\User\\Documents\\Charlie\\LMPred_AMP_Prediction-main\n",
      "Saving Embeddings...\n",
      "Initial Embedding Batch Ending with... 100\n",
      "Initial Embedding Batch Ending with... 200\n",
      "Initial Embedding Batch Ending with... 300\n",
      "Initial Embedding Batch Ending with... 400\n",
      "Initial Embedding Batch Ending with... 500\n",
      "Initial Embedding Batch Ending with... 600\n",
      "Initial Embedding Batch Ending with... 700\n",
      "Initial Embedding Batch Ending with... 800\n",
      "Padding Batch:  0\n",
      "Padding Batch:  100\n",
      "Padding Batch:  200\n",
      "Padding Batch:  300\n",
      "Padding Batch:  400\n",
      "Padding Batch:  500\n",
      "Padding Batch:  600\n",
      "Padding Batch:  700\n",
      "Padding Batch:  800\n",
      "[WinError 2] : 'INSERT_EMBEDDINGS_FOLDER_LOC'\n",
      "C:\\Users\\User\\Documents\\Charlie\\LMPred_AMP_Prediction-main\n",
      "Saving Embeddings...\n"
     ]
    }
   ],
   "source": [
    "T5XL_UNI_EMBED_40.extract_word_embs(PA_X_train, \"PA_X_TRAIN.npy\")\n",
    "T5XL_UNI_EMBED_40.extract_word_embs(PA_X_test, \"PA_X_TEST.npy\")\n",
    "T5XL_UNI_EMBED_40.extract_word_embs(PA_X_val, \"PA_X_VAL.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- N.B. Embedding arrays have been saved as zarr files to the 'Embeddings' folder for the T5 model.\n",
    "- These can be loaded as numpy arrays using the following functions:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Create_Word_Embeddings.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0153e79d7e7d4a59931312ceb66bfcae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0990280d9c704dd38da8e85d8425bc20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0eb90b14c1ef457f8aa5d35ff2f7e309": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0153e79d7e7d4a59931312ceb66bfcae",
      "max": 546,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_228b20a563164b9fba5deb8173ea0b47",
      "value": 546
     }
    },
    "161892df790f44d381a295fff6387583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8ea54d0df714bf8a47f6956196918c8",
      "placeholder": "",
      "style": "IPY_MODEL_da546386e8834a37b124c65c9366b8f4",
      "value": " 546/546 [00:00&lt;00:00, 14.4kB/s]"
     }
    },
    "213954ea9986487ab154b0e030fc7592": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "228b20a563164b9fba5deb8173ea0b47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "28c5b62a652043f5babc44b7814f43ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32a39184d3794617b6296ad4b08db878": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35c540e1c29e42d5bf9420a69a466a32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "470ac6f5da1a4fb8b2a9d75aeb0129ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8239461fdacb4db0985940c8ec032f83",
      "max": 237990,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ddc554d78ae7403991a63d06b357083d",
      "value": 237990
     }
    },
    "4b223e611d394f5b8060740cef7d196f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f3880895a4e48bfac50ca81d844430c",
       "IPY_MODEL_0eb90b14c1ef457f8aa5d35ff2f7e309",
       "IPY_MODEL_161892df790f44d381a295fff6387583"
      ],
      "layout": "IPY_MODEL_59344b3285794e66b3e214470db5a1b2"
     }
    },
    "521418909351429dab44756b7e6585c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c846ccd6af554776858511f962771c12",
      "placeholder": "",
      "style": "IPY_MODEL_89d6029c24d2403cbd8be6988f129a73",
      "value": "Downloading: 100%"
     }
    },
    "59344b3285794e66b3e214470db5a1b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c41efabb32e4d85b1ea1d69feb7f498": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ec2393f8e1f422d831c925e6ecf164c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "657182243e2e4d19aba44edd61e83968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a3a1a3615604bc99d0c02fc8dd29498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71b240f7b76d4328aaafd5aae1220519": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71bff902900c4eb6a77cb8f78fbf33ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ec2393f8e1f422d831c925e6ecf164c",
      "placeholder": "",
      "style": "IPY_MODEL_213954ea9986487ab154b0e030fc7592",
      "value": " 10.5G/10.5G [11:02&lt;00:00, 25.4MB/s]"
     }
    },
    "781e7f95710f40678a6b1287b9bd6826": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f639375bc674825a53f79a72ff77796": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f95e67356584d9ba9743e3faf25ea1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c8b0afd19aa4a1da68499a52acf10c8",
      "max": 1786,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0990280d9c704dd38da8e85d8425bc20",
      "value": 1786
     }
    },
    "8239461fdacb4db0985940c8ec032f83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "883886c874974af881b806d310cc92b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89d6029c24d2403cbd8be6988f129a73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8df260937f9f4ad1827278a25b2487ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91746fa7b3bf4005814058efd093902e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c41efabb32e4d85b1ea1d69feb7f498",
      "placeholder": "",
      "style": "IPY_MODEL_35c540e1c29e42d5bf9420a69a466a32",
      "value": "Downloading: 100%"
     }
    },
    "95c9577ea09f45609b2eaeb6fa504b3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32a39184d3794617b6296ad4b08db878",
      "placeholder": "",
      "style": "IPY_MODEL_c5deb8fa4ff84ca5b3964426034d3e7b",
      "value": " 24.0/24.0 [00:00&lt;00:00, 601B/s]"
     }
    },
    "96db89ceb0164922bc49e88127989c9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c09942041d446db823ca14193b11493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d410c182b2f64aeeb9bd5923cb91db7d",
      "placeholder": "",
      "style": "IPY_MODEL_6a3a1a3615604bc99d0c02fc8dd29498",
      "value": " 232k/232k [00:00&lt;00:00, 657kB/s]"
     }
    },
    "9c8b0afd19aa4a1da68499a52acf10c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d22c013c8f3406eaca7c35bb2a46889": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f3880895a4e48bfac50ca81d844430c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8df260937f9f4ad1827278a25b2487ed",
      "placeholder": "",
      "style": "IPY_MODEL_bc99a3c8c5a2443a9b0bdb16ad09bf21",
      "value": "Downloading: 100%"
     }
    },
    "a6dd1469eabb42f7bd018add5e2d329c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a8ea54d0df714bf8a47f6956196918c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b76d745fe3ab4c929f9a6eefc196010d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c5b62a652043f5babc44b7814f43ac",
      "placeholder": "",
      "style": "IPY_MODEL_883886c874974af881b806d310cc92b8",
      "value": " 1.74k/1.74k [00:00&lt;00:00, 40.3kB/s]"
     }
    },
    "bb85963ad2be403c88707e3f68c41ff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da949c4509b44ef4a4251841a52229a0",
      "placeholder": "",
      "style": "IPY_MODEL_657182243e2e4d19aba44edd61e83968",
      "value": "Downloading: 100%"
     }
    },
    "bc99a3c8c5a2443a9b0bdb16ad09bf21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf0ed98ab2a841d59f93f10205bde6fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c46f0e19ebbf46b996ea87e17251421b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5deb8fa4ff84ca5b3964426034d3e7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c846ccd6af554776858511f962771c12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc4ba0c4ebe54e349057ff67d0393d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edec03194ff94585b69dd2c9e2ae6970",
      "max": 11275562724,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6dd1469eabb42f7bd018add5e2d329c",
      "value": 11275562724
     }
    },
    "ce539392188c4357a9735ad5733dc3e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_91746fa7b3bf4005814058efd093902e",
       "IPY_MODEL_ed19561ff3ce468c916f67158dfc9774",
       "IPY_MODEL_95c9577ea09f45609b2eaeb6fa504b3a"
      ],
      "layout": "IPY_MODEL_c46f0e19ebbf46b996ea87e17251421b"
     }
    },
    "d410c182b2f64aeeb9bd5923cb91db7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da546386e8834a37b124c65c9366b8f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da949c4509b44ef4a4251841a52229a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcfcbbde05b84dbf93d2e64157306bb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb85963ad2be403c88707e3f68c41ff2",
       "IPY_MODEL_cc4ba0c4ebe54e349057ff67d0393d93",
       "IPY_MODEL_71bff902900c4eb6a77cb8f78fbf33ce"
      ],
      "layout": "IPY_MODEL_96db89ceb0164922bc49e88127989c9a"
     }
    },
    "ddc554d78ae7403991a63d06b357083d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e9e25fcb9f4f4f2fae768cbf29fb0427": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf0ed98ab2a841d59f93f10205bde6fd",
      "placeholder": "",
      "style": "IPY_MODEL_71b240f7b76d4328aaafd5aae1220519",
      "value": "Downloading: 100%"
     }
    },
    "ed19561ff3ce468c916f67158dfc9774": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d22c013c8f3406eaca7c35bb2a46889",
      "max": 24,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f790abdaa06e46f0a728dd6c8ffb05ba",
      "value": 24
     }
    },
    "edec03194ff94585b69dd2c9e2ae6970": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1c33096d0784c68914b69d2c3968151": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e9e25fcb9f4f4f2fae768cbf29fb0427",
       "IPY_MODEL_470ac6f5da1a4fb8b2a9d75aeb0129ae",
       "IPY_MODEL_9c09942041d446db823ca14193b11493"
      ],
      "layout": "IPY_MODEL_781e7f95710f40678a6b1287b9bd6826"
     }
    },
    "f790abdaa06e46f0a728dd6c8ffb05ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "faa6c564df4942f4b4702df5c8c020c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_521418909351429dab44756b7e6585c5",
       "IPY_MODEL_7f95e67356584d9ba9743e3faf25ea1a",
       "IPY_MODEL_b76d745fe3ab4c929f9a6eefc196010d"
      ],
      "layout": "IPY_MODEL_7f639375bc674825a53f79a72ff77796"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
